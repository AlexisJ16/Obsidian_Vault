---
title: "Deployment of Machine learning Models"
source: "https://medium.com/@armandoordonez/deployment-of-machine-learning-models-b7c46883fd2d"
author:
  - "[[Jose Armando]]"
published: 2023-04-18
created: 2026-02-18
description: "Deployment of Machine learning Models Here we will create a model with pycaret in Google Collab, and we will deploy it in a Web App with Flask and publish a docker image and Web Application in â€¦"
tags:
  - "clippings"
---


Here we will create a model with pycaret in Google Collab, and we will deploy it in a Web App with Flask and publish a docker image and Web Application in Azure.

1. Train and save a model with Google Collab.
```c
# save pipeline/model
save_model(lr, model_name = 'short_deployment_28042020')
```

[https://github.com/armandoordonez/mlops/blob/main/MLOps.ipynb](https://github.com/armandoordonez/mlops/blob/main/MLOps.ipynb)

2\. Download the trained model ( short\_deployment\_28042020)

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*ia7CFJ8RXxVQa_k6caC-vw.png)

3\. Create a Flask app locally ( For example in Visual Studio Code)

```c
from flask import Flask,request, url_for, redirect, render_template, jsonify
from pycaret.regression import *
import pandas as pd
import pickle
import numpy as np

app = Flask(__name__)

model = load_model('deployment_28042020')
cols = ['age', 'sex', 'bmi', 'children', 'smoker', 'region']

@app.route('/')
def home():
    return render_template("home.html")

@app.route('/predict',methods=['POST'])
def predict():
    int_features = [x for x in request.form.values()]
    final = np.array(int_features)
    data_unseen = pd.DataFrame([final], columns = cols)
    prediction = predict_model(model, data=data_unseen, round = 0)
    # prediction = 1540000
    #print("***************",prediction)
    prediction = int(prediction.prediction_label[0])
    return render_template('home.html',pred='Los gastos esperados son {}'.format(prediction))

@app.route('/predict_api',methods=['POST'])
def predict_api():
    data = request.get_json(force=True)
    data_unseen = pd.DataFrame([data])
    prediction = predict_model(model, data=data_unseen)
    #prediction = 1540000
    output = prediction.Label[0]
    return jsonify(output)

if __name__ == '__main__':
    app.run(debug=True)
```

4\. Run the application locally: [http://127.0.0.1:5000/](http://127.0.0.1:5000/)

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*d5ypqFGQx-qUX9Hdgq0JpA.png)

5\. **Modify the code to make it light:** just for academic purposes we will make a light version of the flask server, this will ease or deployment process.

```c
from flask import Flask,request, url_for, redirect, render_template, jsonify
# from pycaret.regression import *
# import pandas as pd
# import pickle
# import numpy as np
import os

app = Flask(__name__)

# model = load_model('deployment_28042020')
cols = ['age', 'sex', 'bmi', 'children', 'smoker', 'region']

@app.route('/')
def home():
    return render_template("home.html")

@app.route('/predict',methods=['POST', 'GET'])
def predict():
    #int_features = [x for x in request.form.values()]
    #final = np.array(int_features)
    #data_unseen = pd.DataFrame([final], columns = cols)
    # prediction = predict_model(model, data=data_unseen, round = 0)
    prediction = 1540000
    #print("***************",prediction)
    # prediction = int(prediction.prediction_label[0])
    return render_template('home.html',pred='Los gastos esperados son {}'.format(prediction))

@app.route('/predict_api',methods=['POST'])
def predict_api():
    #data = request.get_json(force=True)
    #data_unseen = pd.DataFrame([data])
    #prediction = predict_model(model, data=data_unseen)
    prediction = 1540000
    #output = prediction.Label[0]
    return jsonify(prediction)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 80))
    app.run(debug=True, host='0.0.0.0', port=port)
```
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*OKDNTMC0X_Dr0DDR6Q_BPQ.png)

6\. Create a file called Dockerfile (without extensions)

```c
# start by pulling the python image
FROM python:3.8-alpine

RUN pip install --upgrade pip
RUN pip install virtualenv

ENV VIRTUAL_ENV=/venv
RUN virtualenv venv -p python3

ENV PATH="VIRTUAL_ENV/bin:$PATH"

WORKDIR /app
ADD . /app

# install dependencies
RUN pip install -r requirements.txt

# expose port
EXPOSE 80

# configure the container to run in an executed manner
ENTRYPOINT [ "python" ]

CMD ["app_light.py" ]

# run application
# CMD ["python", "app_light.py"]
```

8\. Test the container locally ( You need a docker installation in your own machine)

```c
cd Dropbox\Courses\MLOps\deployment-heroku-master\mlops

docker build -t mlopsregistro130423.azurecr.io/gastos:latest .
```
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*AhGfZBCLpgGVbRNFLIe6zA.png)

```c
docker run -d -p 80:80 mlopsregistro130423.azurecr.io/gastos
```
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*69NxK0iMstQp8LyievsSrQ.png)

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*7MIIluGobdvzV9HtjXMOAw.png)

9\. Create a docker repository in Azure

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*5Z3OPZaBmMXe1J2oXtT3kQ.png)

10\. Create a virtual machine

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*3BqoEcyQSGnJUSQIdtePog.png)

11\. Connect to the machine

```c
ssh -i server1_key.pem azureuser@172.174.186.164
```
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*_fmkbn8MhOL99ND7DYdgew.png)

12\. Clone the code from github

```c
gh repo clone armandoordonez/mlops
```
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*a3tRzlBkAtOjDMGUWfIz9Q.png)

13\. Create an image and a container in the new server using the previous commands.

```c
azureuser@server1:~$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
azureuser@server1:~$ docker image ls
REPOSITORY                              TAG       IMAGE ID       CREATED         SIZE
mlopsregistro130423.azurecr.io/costos   latest    bd2fbf26fc5b   3 days ago      162MB
ubuntu                                  latest    08d22c0ceb15   5 weeks ago     77.8MB
hello-world                             latest    feb5d9fea6a5   19 months ago   13.3kB
azureuser@server1:~$
```

14\. Try the app on the virtual server

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*2Ei6FRLmvIarOzeJfqaSqQ.png)

15\. Create a Web App from docker

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*90KHwm8XrSyPw838b1aRtg.png)

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*oN36JEYnFfm_GVnOjVGvAg.png)

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*yjS-GgYBN0QXRUcSn1kcfA.png)

12\. Test the Web Application.

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*a6jsuZefnp2D_-cQKcZtYw.png)

## **References:**
[https://www.datacamp.com/tutorial/tutorial-machine-learning-pipelines-mlops-deployment](https://www.datacamp.com/tutorial/tutorial-machine-learning-pipelines-mlops-deployment)
