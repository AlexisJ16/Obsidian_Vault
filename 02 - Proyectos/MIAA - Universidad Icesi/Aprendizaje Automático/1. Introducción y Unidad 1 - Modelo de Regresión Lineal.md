---
tags:
  - unidad-1
  - regresi√≥n-lineal
  - machine-learning
  - estad√≠stica
status: en-progreso
---


> [!ABSTRACT] Panorama Global
> **Lectura obligatoria de inicio:**
> - [ ] üìÑ [Gen AI vs Analytical AI](URL_AQUI) - *Panorama general de la IA.*

---

## üìö Recursos Generales del Curso

**Libro Gu√≠a:**
* üìò **An Introduction to Statistical Learning (ISLP)**
    * [üåê Sitio Web Oficial](https://www.statlearning.com/)
    * [‚¨áÔ∏è Descargar PDF (Versi√≥n Python)](https://www.statlearning.com/)

**Bibliograf√≠a Adicional:**
* üìí *Jim√©nez Moscoso, J. A. (2012)*. √Ålgebra Matricial con Aplicaciones en Estad√≠stica. UNAL.

---

# 1Ô∏è‚É£ Sesi√≥n 1: Introducci√≥n a la Regresi√≥n Lineal

> [!INFO] Objetivo
> Entender la regresi√≥n lineal como herramienta para explicar y predecir el comportamiento de una variable dependiente (Y) a partir de independientes (X).

### üß† Conceptos Clave
1.  **Dependencia entre Variables:**
    * **Covarianza:** Direcci√≥n de la relaci√≥n.
    * **Correlaci√≥n:** Versi√≥n estandarizada (Positiva, Negativa, Nula). *¬°Ojo con Correlaci√≥n vs. Causalidad!*
2.  **Optimizaci√≥n:**
    * **Funci√≥n de p√©rdida OLS:** M√≠nimos Cuadrados Ordinarios (Minimizar el error entre observado y predicho).
    * **Estimaci√≥n de Par√°metros:** Pendiente e Intercepto (Ajuste a los datos).
3.  **Supuestos Te√≥ricos:**
    * ‚úÖ Linealidad
    * ‚úÖ Independencia de errores
    * ‚úÖ Homocedasticidad (varianza constante)
    * ‚úÖ Normalidad de los residuos
    * ‚úÖ Ausencia de multicolinealidad

### üìÖ Actividades de Aprendizaje

> [!TODO] **Antes de la Clase**
> * [ ] **Lectura 1:** [Gen AI vs Analytical AI (Panorama General)](URL_AQUI)
> * [ ] **Lectura 2:** [ISLP - Cap. 2 (Secci√≥n 2.1)](https://www.statlearning.com/)
> * [ ] **Lectura 3:** [ISLP - Cap. 3 (Secci√≥n 3.1)](https://www.statlearning.com/)
> * [ ] **Revisi√≥n Matem√°tica:** Multiplicaci√≥n de Matrices, Transpuestas e Inversas (Para OLS).
> * [ ] **Repaso:** Correlaci√≥n vs. Causalidad.

> [!NOTE] **Durante la Clase**
> - Explicaci√≥n de conceptos y supuestos del modelo te√≥rico.
> - **Parte Pr√°ctica:**
>     - üìÅ [Notebooks - Sesi√≥n 1 (URL_AQUI)]
>     - üìÇ [Data - Sesi√≥n 1 (URL_AQUI)]

> [!EXAMPLE] **Despu√©s de la Clase**
> * [ ] **Buscar:** Un conjunto de datos real.
> * [ ] **An√°lisis:** Identificar predictoras (X) y objetivo (Y).
> * [ ] **Tarea:** Analizar correlaci√≥n y estimar un modelo lineal con `statsmodels` (usando la variable con mayor correlaci√≥n).

---

# 2Ô∏è‚É£ Sesi√≥n 2: Pr√°ctica y Evaluaci√≥n

> [!WARNING] **Evaluaci√≥n**
> Breve cuestionario al inicio para evaluar la sesi√≥n anterior.

### üìÖ Actividades de Aprendizaje

> [!TODO] **Antes de la Clase**
> * [ ] Completar lectura **Gen AI vs Analytical AI**.
> * [ ] Repasar los notebooks de la Sesi√≥n 1.

> [!NOTE] **Durante la Clase (2 Horas)**
> - Trabajo independiente con un set de datos.
> - **Evaluaci√≥n:**
>     - [üîó Quiz 1 - MIAA (Grupo Maestr√≠a en IA)](URL_AQUI)
>     - [üîó Quiz 1 - MCD (Grupo Maestr√≠a en Ciencia de Datos)](URL_AQUI)
> - **Materiales:**
>     - üìÅ [Notebooks - Sesi√≥n 2 (URL_AQUI)]
>     - üìÅ [Notebooks - Sesi√≥n Pr√°ctica (URL_AQUI)]

---

# 3Ô∏è‚É£ Sesi√≥n 3: Optimizaci√≥n y Regresi√≥n Avanzada

> [!INFO] Objetivo
> Profundizar en m√©todos de optimizaci√≥n (OLS vs Gradiente Descendente) y extender el modelo a regresiones m√∫ltiples y polin√≥micas.

### üß† Conceptos Clave
1.  **Algoritmo OLS (M√≠nimos Cuadrados Ordinarios):**
    * Soluci√≥n anal√≠tica. Interpretaci√≥n matem√°tica y geom√©trica.
    * *Limitaci√≥n:* Escalabilidad y sensibilidad a at√≠picos.
2.  **Gradiente Descendente (Gradient Descent):**
    * M√©todo iterativo (Num√©rico).
    * *Key Terms:* Learning Rate, Convergencia, Iteraciones.
    * *Uso:* Big Data y modelos complejos.
3.  **Regresi√≥n Lineal M√∫ltiple:**
    * Problemas frecuentes: Multicolinealidad, Sobreajuste.
4.  **Regresi√≥n Lineal Polin√≥mica:**
    * Capturar relaciones no lineales (linealidad en par√°metros, no en datos).
    * *Riesgo:* Sobreajuste y extrapolaci√≥n.

### üìÖ Actividades de Aprendizaje

> [!TODO] **Antes de la Clase**
> * [ ] **Lectura:** [ISLP - Cap. 3 (Secciones 3.2 a 3.4)](https://www.statlearning.com/)

> [!NOTE] **Durante la Clase**
> - Teor√≠a de optimizaci√≥n y aplicaci√≥n de regresi√≥n m√∫ltiple y polin√≥mica.
> - **Materiales:**
>     - üìÅ [Notebooks - Sesi√≥n 3 (URL_AQUI)]
>     - üìÇ [Data - Sesi√≥n 3 (URL_AQUI)]

> [!EXAMPLE] **Despu√©s de la Clase**
> * [ ] **Pr√°ctica:** Aplicar regresi√≥n lineal a un dataset real e interpretar resultados.
> * [ ] **Lectura Complementaria:** *Myers et al. (2012)* - Generalized Linear Model.

---

# 4Ô∏è‚É£ Sesi√≥n 4: Pr√°ctica Grupal y Reporte

> [!TIP] Din√°mica
> Trabajo en grupos aleatorios de 4 personas. Generaci√≥n de reporte comparativo.

### üìÖ Actividades de Aprendizaje

> [!TODO] **Antes de la Clase**
> * [ ] Revisar: Regresi√≥n M√∫ltiple y Polin√≥mica.

> [!NOTE] **Durante la Clase (2 Horas)**
> - Descargar Notebook y datos para trabajar en grupo.
> - **Materiales:**
>     - ‚¨áÔ∏è [Descargar Notebook y Datos (URL_AQUI)]

---